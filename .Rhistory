i <- NULL
set <- function(y) {
x <<- y
i <<- NULL
}
get <- function() x
setinverse <- function(solve) i <<- solve
getinverse <- function() i
list(set = set, get = get, setinverse = setinverse, getinverse = getinverse)
}
## Check for a stored value of the inverse of matrix 'x', and if not available, calculate inverse
cacheSolve <- function(x, ...) {
i <- x$getinverse()
if(!is.null(i)) {
message("getting cached data")
return(i)
}
data <- x$get()
i <- solve(data, ...)
x$setinverse(i)
return(i)
}
makeCacheMatrix <- function(x = matrix()) {
i <- NULL
set <- function(y) {
x <<- y
i <<- NULL
}
get <- function() x
setinverse <- function(solve) i <<- solve
getinverse <- function() i
list(set = set, get = get, setinverse = setinverse, getinverse = getinverse)
}
## Check for a stored value of the inverse of matrix 'x', and if not available, calculate inverse
cacheSolve <- function(x, ...) {
i <- x$getinverse()
if(!is.null(i)) {
message("getting cached data")
return(i)
}
data <- x$get()
i <- solve(data, ...)
x$setinverse(i)
return(i)
}
Status API Training Shop Blog About Pricing
makeCacheMatrix <- function(x = matrix()) {
i <- NULL
set <- function(y) {
x <<- y
i <<- NULL
}
get <- function() x
setinverse <- function(solve) i <<- solve
getinverse <- function() i
list(set = set, get = get, setinverse = setinverse, getinverse = getinverse)
}
## Check for a stored value of the inverse of matrix 'x', and if not available, calculate inverse
cacheSolve <- function(x, ...) {
i <- x$getinverse()
if(!is.null(i)) {
message("getting cached data")
return(i)
}
data <- x$get()
i <- solve(data, ...)
x$setinverse(i)
return(i)
}
a<-diag(5,5)
b<-makeCacheMatrix(a)
c<-cacheSolve(b)
a
c
makeCacheMatrix <- function(x = matrix()) {
inv <- NULL
set <- function(y) {
x <<- y
inv <<- NULL
}
get <- function() x
setinverse <- function(inverse) inv <<- inverse
getinverse <- function() inv
list(set = set, get = get,
setinverse = setinverse,
getinverse = getinverse)
}
cacheSolve <- function(x, ...) {
## Return a matrix that is the inverse of 'x'
inv <- x$getinverse()
if(!is.null(inv)) {
message("getting cached data")
return(inv)
}
data <- x$get()
# assuming input matrix is invertible and square
inv <- solve(data, ...)
x$setinverse(inv)
inv
}
Status API Training Shop Blog About Pricing
cacheSolve <- function(x, ...) {
## Return a matrix that is the inverse of 'x'
inv <- x$getinverse()
if(!is.null(inv)) {
message("getting cached data")
return(inv)
}
data <- x$get()
# assuming input matrix is invertible and square
inv <- solve(data, ...)
x$setinverse(inv)
inv
}
a<-diag(5,5)
b<-makeCacheMatrix(a)
c<-cacheSolve(b)
a
c
quit()
hilbert <- function(n){
i <- 1:n
1/outer(i-1, i, "+")
}
x<-hilbert(1000)
system.time(svd(x))
system.time({
n<-1000
r<-numeric(n)
for(i in 1:n){
x<-rnorm(n)
r[i]<-mean(x)
}
})
summaryRprof()
set.seed(1)
rpois(5,2)
set.seed(10)
x<-rep(0:1, each =5)
e<-rnorm(10,0,20)
y<-0.5+2*x+e
plot(x,y)
set.seed(1)
rpois(5,2)
quit()
swirl()
library(swirl)
swirl()
ls()
class(plants)
dim(plants)
nrow(plants)
ncol(plants)
object.size(plants)
names(plants)
head(plants)
head(plants,10)
tail(plants,15)
summary(plants)
table(plants$Active_Growth_Period)
str()
str(plants)
?sample
sample(1:6, 4, replace = TRUE)
sample(1:6, 4, replace = TRUE)
sample(1:20, 10, replace = FALSE)
sample(1:20, 10)
LETTERS
sample(LETTERS)
sample(c(0,1), 100, replace = TRUE, prob=c(0.3, 0.7))
flips <- sample(c(0,1), 100, replace = TRUE, prob=c(0.3, 0.7))
flips
sum(flips)
?rbinom
rbinom(1, size = 100, prob = 0.7)
flips2<-rbinom(1, size = 100, prob = 0.7)
flips2 <- rbinom(n=100, size = 1, prob=0.7)
flips2
sum(flips2)
rnorm()
?rnorm
rnorm(10)
rnorm(10, 100, 25)
?rpois()
rpois(5,10)
my_pois <- replicate(100, rpois(5,10))
my_pos
my_pois
cm<-colMeans(my_pois)
hist(cm)
data(cars)
?cars
head(cars)
plot(cars)
?plot()
?plot
plot(cars$speed, cars$dist)
plot(cars$dist, cars$speed)
plot(cars)
plot(x = cars$speed, y = cars$dist, xlab = "Speed")
plot(x = cars$speed, y = cars$dist, xlab = "Speed", ylab="Stopping Distance")
plot(x = cars$speed, y = cars$dist, ylab="Stopping Distance")
plot(x = cars$speed, y = cars$dist, xlab = "Speed", ylab="Stopping Distance")
plot(cars, main="My Plot")
plot(cars, sub = "My Plot Subtitle")
plot(cars, col = 2)
plot(cars, xlim=c(10,15))
?points
plot(cars, pch=2)
data(mtcars)
?boxplot
boxplot(mpg ~ cyl, data= mtcars)
hist(mtcars$mpg)
quit()
library(XML)
library(dplyr)
options(width=105)
chicago <-readRDS("chicago.rds")
q()
library(swirl)
swirl()
library(dplyr)
cran<-tbl_df(mydf)
rm("mydf")
cran
?group_by
group_by(.cran, by_package)
by_package <- group_by(.cran, package)
by_package <- group_by(cran, package)
by_package
summarise(by_package,mean(size))
?summarise
submit()
submit()
tbl()
pack_sum
quantile(pack_sum$count, probs=0.99)
top_counts <-qunatil(pack_sum$count, probs=0.99)
top_counts <-qunatile(pack_sum$count, probs=0.99)
top_counts <-quantile(pack_sum$count, probs=0.99)
top_counts<-filter(pack_sum, count > 679)
top_counts
View(top_counts)
?arrange
top_counts_sorted <-arrange(top_counts,desc(count()))
top_counts_sorted <-arrange(top_counts,desc(count))
View(top_counts_sorted)
quantile(pack_sum$unique, probs=0.99)
top_unique<-filter(pack_sum, unique > 465)
View(top_unique)
top_unique_sorted <- arrange(top_unique, desc(unique))
View(top_unique_sorted)
submit()
submit()
submit()
View(result3)
submit()
?mutate
submit()
submit()
submit()
library(tidyr)
students
?gather
gather(students)
gather(students, sex, count, -grade)
students2
res<-gather(students2, sex_class, value)
res<-gather(students2, sex_class, count, -grade)
res
?separate
separate(res, sex_class, c("sex","class"))
submit()
submit()
students3
?gather
submit()
?spread
submit()
submit()
extract_numeric("class5")
?mutate
submit()
submit()
reset()
?extract_numeric
submit()
students4
submit()
?unique
submit()
submit()
submit()
passed
failed
?mutate
mutate(passed, status=c("passed"))
passed <- passed %>% mutated(status = "passed")
passed <- passed %>% mutate(status = "passed")
failed <- failed %>% mutate(status = "failed")
?bind_rows
bind_rows(passed, failed)
sat
?gather
?separate
submit()
submit()
submit()
q90
q()
getwd()
url<-file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv")
download.file(url, destfile="./quiz3_1.csv", method="curl")
url<-("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv")
download.file(url, destfile="./quiz3_1.csv", method="curl")
q1<-read.csv("quiz3_1.csv", header=TRUE)
q1
library(dplyr)
library(plyr)
qes1<-mutate(q1, agricultureLogical=facter((ACR==3 & AGS==6), levels=c(TRUE, FALSE)))
qes1<-mutate(q1, agricultureLogical=factor((ACR==3 & AGS==6), levels=c(TRUE, FALSE)))
q1<-mutate(q1, agricultureLogical=factor((ACR==3 & AGS==6), levels=c(TRUE, FALSE)))
head(row.names(q1[which(q1$agricultureLogical==TRUE),]), 3)
url2<-" https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg "
url2<-"https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
download.file(url2, destfile="./quiz2.jpg", method="curl")
library(jpeg)
install.packages("jpeg")
library(jpeg)
?read.jpeg
?read.jpg
?readJPEG
q2<-readJPEG("./q2.jpg", native=TRUE)
q2<-readJPEG("q2.jpg", native=TRUE)
q2<-readJPEG(source="q2.jpg", native=TRUE)
q2<-readJPEG("quiz2.jpg", native=TRUE)
q2
?quantile
quantile(q2, c(30,80))
quantile(q2, c(0.3,0.8))
url3<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(url3, destfile="./quiz3.csv", method="curl")
download.file(url3, destfile="./quiz3_1.csv", method="curl")
url4<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(url4,destfile="./quiz3_2.csv", method="curl")
q3_1<-read.csv("quiz3_1.csv", header=TRUE, skip=3, sep=",")
a3_2<-read.csv("quiz3_2.csv", header=TRUE)
q3_1
q3_1<-q3_1[2:191, c(1,2,4,5)]
q3_1
rownames(q3_1) <-NULL
q3_1
q3_1 <- rename(q3_1, CountryCode = X)
q3_2
q3_1
q3_2<-read.csv("quiz3_2.csv", header=TRUE)
q3_2
q3_1 <-rename(q3_1, CountryCode=X)
?rename
q3_1
rownames(q3_1)<-NULL
q3_1
q3_1 <- rename(q3_1, CountryCode =X)
q3_merge<-join(q3_1,q3_2)
q3_merge
# load the datasets
q3_1 <- read.csv("q3_1.csv", header = TRUE, skip = 3, sep = ",")
q3_2 <- read.csv("q3_2.csv", header = TRUE)
# reshaping data
q3_1 <- q3_1[2:191, c(1,2,4,5)]
rownames(q3_1) <- NULL
q3_1 <- rename(q3_1, CountryCode = X)
# merge two datasets
q3_merge <- join(q3_1, q3_2)
# show the number of matches
sum(!is.na(unique(q3_merge$Ranking)))
# convert the data type of Ranking
q3_merge$Ranking <- as.numeric(as.character(q3_merge$Ranking))
# show the 13th country after sort decending
q3_merge <- arrange(q3_merge, desc(Ranking))
q3_merge[13,3]
income_group <-group_by(q3_merge, Income.Group)
summarize(income_group, avg=mean(Ranking, na.rm=TRUE))
income_group
q3_1
q3_2
dt[,mean(rankingGDP, na.rm=TRUE), by=Income.Group]
q3_3<-data.table(read.csv(q3_2))
libarary(data.table)
library(data.table)
q3_3<-data.table(read.csv(q3_2))
clear()
library(dplyr)
library(plyr)
url<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
url2<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
q3_1<-read.csv("./quiz3_1.csv")
q3_1<-read.csv("./quiz3_1.csv", header=TRUE)
library(read.table)
library(data.table)
dtGDP<-data.table(read.csv(q3_1, skip=4, nrow=215))
dtGDP<-data.table(read.csv("quiz3_1.csv", skip=4, nrow=215))
dtGDP
dtGDP <- dtGDP[X !=""]
dtGDP
dtGDP<-dtGDP[, list(X,X.1,X.3,X.4)]
dtGDP
setnames(dtGDP, c("X","X.1","X.3","X.4"), c("CountryCode", "rankingGDP","Long.Name", "gdp"))
dtEd<-data.table(read.csv("quiz3_2.csv"))
dtEd
dt<-merge(dtGDP, dtEd, all=TRUE, by=c("CountryCode"))
dt
sum(!is.na(unique(dt$rankingGDP)))
dt[order(rankingGDP, descending=TRUE), list(CountryCode, Long.Name.x, Long.Name.y,rankingGDP, gdp)]
dt[order(rankingGDP, descending=TRUE), list(CountryCode, Long.Name.x, Long.Name.y,rankingGDP, gdp)][13]
dt[,mean(rankingGDP, na.rm=TRUE), by=Income.Group]
breaks<-quantile(dt$rankingGDP, probs = seq(0,1,0.2), na.rm=TRUE)
dt$quantileGDP <- cut(dt$rankingGDP, breaks = breaks)
dt[Income.Group == "Lower middle income", .N, by=c("Income.Group", "quantileGDP")]
quit()
library(swirl)
swirl()
Sys.getlocale("LC_TIME")
library(lubridate)
help(package = lubridate)
this_day<-today()
this_day
year(this_day)
wdqy(this_day)
wday(this_day)
wday(this_day, label=TRUE)
this_moment <- now()
this_comment
this_comment()
this_moment
minute(this_moment)
my_date <-ymd("1989-05-17")
my_date
class(my_date)
ymd("1989 May 17")
ymd("March 12, 1975")
mdy("March 12, 1975")
dmy("25081985")
dmy(25081985)
ymd("192012")
ymd("192012--")
ymd("1920/1/2")
dt1<-date-time()
dt1<-ymd("1920/1/2")
dt1()
?dt1
dt1
dt1<-ymd_hms()
ymd_hms(dt1)
ymd_hms("03:22:14"
)
hms("03:22:14")
dt2
ymd(dt2)
update(this_moment, hours = 8, minutes = 34, seconds = 55)
this_moment
this_moment(update())
update(this_moment)
this_moment<-updqte(this_moment())
this_moment<-update(this_moment())
this_moment
update(this_moment, hours = 10, minutes = 16, seconds = 0)
update(this_moment, hours = 5, minutes = 56, seconds = 0)
this_moment<-update(this_moment, hours = 5, minutes = 57, seconds=0)
this_moment
?now
nyc<-now(tzone="America/New_York")
nyc
depart<-nyc+days(2)
depart
depart<-update(depart, hours = 17, minutes = 34)
depart
depart+hours(15)+minutes(50)
arrive <-depart +hours(15)+minutes(50)
?with_tz
arrive<-with_tz(arrive, tzone="Asia/Hong_Kong")
arrive
mdy("June 17, 2008")
last_time<-mdy("June 17, 2008", tz="Singapore")
last_time
?new_interval
how_long<-new_interval(depart, arrive)
how_long<-new_interval(last_time,arrive)
as.period(how_long)
stopwatch()
q()
url<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
f<-file.path(getwd(),"ss06hid.csv")
download.file(url,f)
dt<-data.table(read.csv(f))
packages <- c("data.table", "quantmod")
sapply(packages, require, character.only=TRUE, quietly=TRUE)
load.packages("data.table")
dt<-data.table(read.csv(f))
varNames <- names(dt)
varNamesSplit <- strsplit(varNames, "wgtp")
varNamesSplit[[123]]
setwd("~/Desktop/Coursera/Getting and Cleaning Data/Week 4/Project")
getwd()
source("run_analysis.R")
source("run_analysis.R")
ll
ls
ls()
git init
git
git
